{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lstm _ pytorch _ nextwordpredictor\n",
        "---------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfcpnluzLzo",
        "outputId": "e47d12c7-db63-4d59-a439-44808d5bdc81"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fLwm0Y_MzVuh"
      },
      "outputs": [],
      "source": [
        "document = \"\"\"\n",
        "What is the Artificial Intelligence (AI) Mentorship Program?\n",
        "This program is a structured mentorship designed to help learners understand, build, and deploy Artificial Intelligence systems from fundamentals to applied use cases.\n",
        "\n",
        "What is the course fee for the AI Mentorship Program?\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 999/month.\n",
        "\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 6 months. So the total course fee becomes 999*6 = Rs 6000 (approx.)\n",
        "\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python for AI\n",
        "Mathematics for AI (Linear Algebra, Probability, Statistics)\n",
        "Data Handling and Preprocessing\n",
        "Machine Learning Fundamentals\n",
        "Supervised Learning Algorithms\n",
        "Unsupervised Learning Algorithms\n",
        "Introduction to Neural Networks\n",
        "Deep Learning Basics\n",
        "Natural Language Processing (NLP) Fundamentals\n",
        "Computer Vision Basics\n",
        "Model Evaluation and Optimization\n",
        "AI Project Development\n",
        "Model Deployment Basics\n",
        "Ethics and Responsible AI\n",
        "Case Studies and Real-world AI Applications\n",
        "\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "Yes, both Deep Learning and NLP are core parts of the curriculum.\n",
        "\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes, all sessions are recorded. You can watch the recordings anytime during your subscription period.\n",
        "\n",
        "Where can I find the class schedule?\n",
        "You will find the month-wise class schedule in your dashboard after registration.\n",
        "\n",
        "What is the time duration of all the live sessions?\n",
        "Each live session is approximately 2 hours long.\n",
        "\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish (Hindi + English)\n",
        "\n",
        "How will I be informed about the upcoming class?\n",
        "You will receive an email notification before every live session.\n",
        "\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes. The program starts from fundamentals and is suitable for non-tech backgrounds with basic computer knowledge.\n",
        "\n",
        "I am late, can I join the program in the middle?\n",
        "Yes, you can join the program at any time.\n",
        "\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you subscribe, all previous sessions will be available in your dashboard.\n",
        "\n",
        "Where do I have to submit the tasks and assignments?\n",
        "Assignments are self-evaluated. Solutions will be provided for learning and comparison.\n",
        "\n",
        "Will we do real-world AI case studies in the program?\n",
        "Yes, multiple real-world AI case studies will be discussed and implemented.\n",
        "\n",
        "Where can we contact you for queries?\n",
        "You can mail us at support.ai@mentorship.com\n",
        "\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments?\n",
        "All payments must be made through our official website.\n",
        "\n",
        "Can we pay the entire amount at once?\n",
        "No, the program follows a strict monthly subscription model.\n",
        "\n",
        "What is the validity of the monthly subscription?\n",
        "The validity is 30 days from the date of payment.\n",
        "\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "There is a 7-day refund policy from the date of payment.\n",
        "\n",
        "I am living outside India and unable to make payments. What should I do?\n",
        "Please contact us via email for alternative payment options.\n",
        "\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "You can watch videos as long as your subscription is active. After completing all installments, you will retain access till the program’s end date.\n",
        "\n",
        "Why lifetime validity is not provided?\n",
        "Lifetime access is not provided due to the low course fee and continuous content updates.\n",
        "\n",
        "Where can I ask doubts after the session?\n",
        "You can submit your doubts using the doubt-clearing form available in your dashboard.\n",
        "\n",
        "If I join the program late, can I still ask doubts from past sessions?\n",
        "Yes, you can raise doubts related to past sessions as well.\n",
        "\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are two criteria:\n",
        "1. Completion of all monthly payments\n",
        "2. Attempting all assessments and projects\n",
        "\n",
        "I am joining late. How can I pay for previous months?\n",
        "You will get an option in your dashboard to clear pending months.\n",
        "\n",
        "Is placement assistance included in this program?\n",
        "Yes, placement assistance is included but placement is not guaranteed. The assistance includes:\n",
        "Portfolio and project guidance\n",
        "Resume reviews\n",
        "Mock interviews\n",
        "Career guidance sessions\n",
        "Job search strategy discussions\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "7fe012b9-4425-46b0-f109-e3174731f277"
      },
      "outputs": [],
      "source": [
        "# # Tokenization\n",
        "# nltk.download(\"punkt\")\n",
        "# nltk.download(\"punkt_tab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "outputs": [],
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "63c6bf46-c4de-4126-8c12-5f574f70a545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'artificial': 4,\n",
              " 'intelligence': 5,\n",
              " '(': 6,\n",
              " 'ai': 7,\n",
              " ')': 8,\n",
              " 'mentorship': 9,\n",
              " 'program': 10,\n",
              " '?': 11,\n",
              " 'this': 12,\n",
              " 'a': 13,\n",
              " 'structured': 14,\n",
              " 'designed': 15,\n",
              " 'to': 16,\n",
              " 'help': 17,\n",
              " 'learners': 18,\n",
              " 'understand': 19,\n",
              " ',': 20,\n",
              " 'build': 21,\n",
              " 'and': 22,\n",
              " 'deploy': 23,\n",
              " 'systems': 24,\n",
              " 'from': 25,\n",
              " 'fundamentals': 26,\n",
              " 'applied': 27,\n",
              " 'use': 28,\n",
              " 'cases': 29,\n",
              " '.': 30,\n",
              " 'course': 31,\n",
              " 'fee': 32,\n",
              " 'for': 33,\n",
              " 'follows': 34,\n",
              " 'monthly': 35,\n",
              " 'subscription': 36,\n",
              " 'model': 37,\n",
              " 'where': 38,\n",
              " 'you': 39,\n",
              " 'have': 40,\n",
              " 'make': 41,\n",
              " 'payments': 42,\n",
              " 'of': 43,\n",
              " 'rs': 44,\n",
              " '999/month': 45,\n",
              " 'total': 46,\n",
              " 'duration': 47,\n",
              " '6': 48,\n",
              " 'months': 49,\n",
              " 'so': 50,\n",
              " 'becomes': 51,\n",
              " '999': 52,\n",
              " '*': 53,\n",
              " '=': 54,\n",
              " '6000': 55,\n",
              " 'approx': 56,\n",
              " 'syllabus': 57,\n",
              " 'we': 58,\n",
              " 'will': 59,\n",
              " 'be': 60,\n",
              " 'covering': 61,\n",
              " 'following': 62,\n",
              " 'modules': 63,\n",
              " ':': 64,\n",
              " 'python': 65,\n",
              " 'mathematics': 66,\n",
              " 'linear': 67,\n",
              " 'algebra': 68,\n",
              " 'probability': 69,\n",
              " 'statistics': 70,\n",
              " 'data': 71,\n",
              " 'handling': 72,\n",
              " 'preprocessing': 73,\n",
              " 'machine': 74,\n",
              " 'learning': 75,\n",
              " 'supervised': 76,\n",
              " 'algorithms': 77,\n",
              " 'unsupervised': 78,\n",
              " 'introduction': 79,\n",
              " 'neural': 80,\n",
              " 'networks': 81,\n",
              " 'deep': 82,\n",
              " 'basics': 83,\n",
              " 'natural': 84,\n",
              " 'language': 85,\n",
              " 'processing': 86,\n",
              " 'nlp': 87,\n",
              " 'computer': 88,\n",
              " 'vision': 89,\n",
              " 'evaluation': 90,\n",
              " 'optimization': 91,\n",
              " 'project': 92,\n",
              " 'development': 93,\n",
              " 'deployment': 94,\n",
              " 'ethics': 95,\n",
              " 'responsible': 96,\n",
              " 'case': 97,\n",
              " 'studies': 98,\n",
              " 'real-world': 99,\n",
              " 'applications': 100,\n",
              " 'part': 101,\n",
              " 'yes': 102,\n",
              " 'both': 103,\n",
              " 'are': 104,\n",
              " 'core': 105,\n",
              " 'parts': 106,\n",
              " 'curriculum': 107,\n",
              " 'if': 108,\n",
              " 'i': 109,\n",
              " 'miss': 110,\n",
              " 'live': 111,\n",
              " 'session': 112,\n",
              " 'get': 113,\n",
              " 'recording': 114,\n",
              " 'all': 115,\n",
              " 'sessions': 116,\n",
              " 'recorded': 117,\n",
              " 'can': 118,\n",
              " 'watch': 119,\n",
              " 'recordings': 120,\n",
              " 'anytime': 121,\n",
              " 'during': 122,\n",
              " 'your': 123,\n",
              " 'period': 124,\n",
              " 'find': 125,\n",
              " 'class': 126,\n",
              " 'schedule': 127,\n",
              " 'month-wise': 128,\n",
              " 'in': 129,\n",
              " 'dashboard': 130,\n",
              " 'after': 131,\n",
              " 'registration': 132,\n",
              " 'time': 133,\n",
              " 'each': 134,\n",
              " 'approximately': 135,\n",
              " '2': 136,\n",
              " 'hours': 137,\n",
              " 'long': 138,\n",
              " 'spoken': 139,\n",
              " 'by': 140,\n",
              " 'instructor': 141,\n",
              " 'hinglish': 142,\n",
              " 'hindi': 143,\n",
              " '+': 144,\n",
              " 'english': 145,\n",
              " 'how': 146,\n",
              " 'informed': 147,\n",
              " 'about': 148,\n",
              " 'upcoming': 149,\n",
              " 'receive': 150,\n",
              " 'an': 151,\n",
              " 'email': 152,\n",
              " 'notification': 153,\n",
              " 'before': 154,\n",
              " 'every': 155,\n",
              " 'do': 156,\n",
              " 'am': 157,\n",
              " 'non-tech': 158,\n",
              " 'background': 159,\n",
              " 'starts': 160,\n",
              " 'suitable': 161,\n",
              " 'backgrounds': 162,\n",
              " 'with': 163,\n",
              " 'basic': 164,\n",
              " 'knowledge': 165,\n",
              " 'late': 166,\n",
              " 'join': 167,\n",
              " 'middle': 168,\n",
              " 'at': 169,\n",
              " 'any': 170,\n",
              " 'join/pay': 171,\n",
              " 'able': 172,\n",
              " 'see': 173,\n",
              " 'past': 174,\n",
              " 'lectures': 175,\n",
              " 'once': 176,\n",
              " 'subscribe': 177,\n",
              " 'previous': 178,\n",
              " 'available': 179,\n",
              " 'submit': 180,\n",
              " 'tasks': 181,\n",
              " 'assignments': 182,\n",
              " 'self-evaluated': 183,\n",
              " 'solutions': 184,\n",
              " 'provided': 185,\n",
              " 'comparison': 186,\n",
              " 'multiple': 187,\n",
              " 'discussed': 188,\n",
              " 'implemented': 189,\n",
              " 'contact': 190,\n",
              " 'queries': 191,\n",
              " 'mail': 192,\n",
              " 'us': 193,\n",
              " 'support.ai': 194,\n",
              " '@': 195,\n",
              " 'mentorship.com': 196,\n",
              " 'payment/registration': 197,\n",
              " 'related': 198,\n",
              " 'questions': 199,\n",
              " 'our': 200,\n",
              " 'must': 201,\n",
              " 'made': 202,\n",
              " 'through': 203,\n",
              " 'official': 204,\n",
              " 'website': 205,\n",
              " 'pay': 206,\n",
              " 'entire': 207,\n",
              " 'amount': 208,\n",
              " 'no': 209,\n",
              " 'strict': 210,\n",
              " 'validity': 211,\n",
              " '30': 212,\n",
              " 'days': 213,\n",
              " 'date': 214,\n",
              " 'payment': 215,\n",
              " 'don': 216,\n",
              " '’': 217,\n",
              " 't': 218,\n",
              " 'like': 219,\n",
              " 'making': 220,\n",
              " 'refund': 221,\n",
              " 'policy': 222,\n",
              " 'there': 223,\n",
              " '7-day': 224,\n",
              " 'living': 225,\n",
              " 'outside': 226,\n",
              " 'india': 227,\n",
              " 'unable': 228,\n",
              " 'should': 229,\n",
              " 'please': 230,\n",
              " 'via': 231,\n",
              " 'alternative': 232,\n",
              " 'options': 233,\n",
              " 'post': 234,\n",
              " 'till': 235,\n",
              " 'when': 236,\n",
              " 'view': 237,\n",
              " 'paid': 238,\n",
              " 'videos': 239,\n",
              " 'on': 240,\n",
              " 'as': 241,\n",
              " 'active': 242,\n",
              " 'completing': 243,\n",
              " 'installments': 244,\n",
              " 'retain': 245,\n",
              " 'access': 246,\n",
              " 's': 247,\n",
              " 'end': 248,\n",
              " 'why': 249,\n",
              " 'lifetime': 250,\n",
              " 'not': 251,\n",
              " 'due': 252,\n",
              " 'low': 253,\n",
              " 'continuous': 254,\n",
              " 'content': 255,\n",
              " 'updates': 256,\n",
              " 'ask': 257,\n",
              " 'doubts': 258,\n",
              " 'using': 259,\n",
              " 'doubt-clearing': 260,\n",
              " 'form': 261,\n",
              " 'still': 262,\n",
              " 'raise': 263,\n",
              " 'well': 264,\n",
              " 'certificate': 265,\n",
              " 'placement': 266,\n",
              " 'assistance': 267,\n",
              " 'criteria': 268,\n",
              " 'two': 269,\n",
              " '1.': 270,\n",
              " 'completion': 271,\n",
              " '2.': 272,\n",
              " 'attempting': 273,\n",
              " 'assessments': 274,\n",
              " 'projects': 275,\n",
              " 'joining': 276,\n",
              " 'option': 277,\n",
              " 'clear': 278,\n",
              " 'pending': 279,\n",
              " 'included': 280,\n",
              " 'but': 281,\n",
              " 'guaranteed': 282,\n",
              " 'includes': 283,\n",
              " 'portfolio': 284,\n",
              " 'guidance': 285,\n",
              " 'resume': 286,\n",
              " 'reviews': 287,\n",
              " 'mock': 288,\n",
              " 'interviews': 289,\n",
              " 'career': 290,\n",
              " 'job': 291,\n",
              " 'search': 292,\n",
              " 'strategy': 293,\n",
              " 'discussions': 294}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build vocab\n",
        "vocab = {\"<unk>\": 0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "    if token not in vocab:\n",
        "        vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOOEZ94P0dQ1",
        "outputId": "0cd5b6e3-442b-4cc4-b6ed-241f4f7360d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "295"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RefNavJe1Cva"
      },
      "outputs": [],
      "source": [
        "input_sentences = document.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "outputs": [],
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "    numerical_sentence = []\n",
        "\n",
        "    for token in sentence:\n",
        "        if token in vocab:\n",
        "            numerical_sentence.append(vocab[token])\n",
        "        else:\n",
        "            numerical_sentence.append(vocab[\"<unk>\"])\n",
        "\n",
        "    return numerical_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eu66Zo3e1Wh9"
      },
      "outputs": [],
      "source": [
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "    input_numerical_sentences.append(\n",
        "        text_to_indices(word_tokenize(sentence.lower()), vocab)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxJesAQC1et3",
        "outputId": "14e297a6-4d7e-4ead-964f-7d48d65ff4fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(input_numerical_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "outputs": [],
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "    for i in range(1, len(sentence)):\n",
        "        training_sequence.append(sentence[: i + 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aGJ0fy7swk",
        "outputId": "97d50462-db1e-4f04-c628-b7d258d7e482"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "731"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(training_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrFzZ4DD8Anu",
        "outputId": "bead6f75-7984-4879-e7d6-e8a2f81530ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_sequence[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "dc0971ee-ecb8-4061-c6aa-c5d751bb1da0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "    len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bIcIRd088EN",
        "outputId": "b4781829-742e-4764-f122-f143310af51b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_sequence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "outputs": [],
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "    padded_training_sequence.append([0] * (max(len_list) - len(sequence)) + sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZssF989X-4",
        "outputId": "48e3413e-fd8d-4226-c3df-6f5031514c5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(padded_training_sequence[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "outputs": [],
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKvdXa79yxV",
        "outputId": "b426db0b-fdca-41f9-818e-a237c229f7d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   2,   3,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 291, 292],\n",
              "        [  0,   0,   0,  ..., 291, 292, 293],\n",
              "        [  0,   0,   0,  ..., 292, 293, 294]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_training_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Tz8fwCok90m0"
      },
      "outputs": [],
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "7095458b-a2e8-4dc7-f150-80fd56d2c281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0,   0, 291],\n",
              "        [  0,   0,   0,  ...,   0, 291, 292],\n",
              "        [  0,   0,   0,  ..., 291, 292, 293]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "f2cca2e3-da31-4ef5-bc13-593203462048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  10,   2,  13,  14,\n",
              "          9,  15,  16,  17,  18,  19,  20,  21,  20,  22,  23,   4,   5,  24,\n",
              "         25,  26,  16,  27,  28,  29,  30,   2,   3,  31,  32,  33,   3,   7,\n",
              "          9,  10,  11,  31,  34,  13,  35,  36,  37,  38,  39,  40,  16,  41,\n",
              "         35,  42,  43,  44,  45,  30,   2,   3,  46,  47,  43,   3,  31,  11,\n",
              "         46,  47,  43,   3,  31,   2,  48,  49,  30,  50,   3,  46,  31,  32,\n",
              "         51,  52,  53,  48,  54,  44,  55,   6,  56,  30,   8,   2,   3,  57,\n",
              "         43,   3,   9,  10,  11,  59,  60,  61,   3,  62,  63,  64,  33,   7,\n",
              "         33,   7,   6,  67,  68,  20,  69,  20,  70,   8,  72,  22,  73,  75,\n",
              "         26,  75,  77,  75,  77,  16,  80,  81,  75,  83,  85,  86,   6,  87,\n",
              "          8,  26,  89,  83,  90,  22,  91,  92,  93,  94,  83,  22,  96,   7,\n",
              "         98,  22,  99,   7, 100,  82,  75,  22,  87,  60,  13, 101,  43,  12,\n",
              "         10,  11,  20, 103,  82,  75,  22,  87, 104, 105, 106,  43,   3, 107,\n",
              "         30, 108, 109, 110,  13, 111, 112,  11,  59, 109, 113,  13, 114,  43,\n",
              "          3, 112,  11,  20, 115, 116, 104, 117,  30,  39, 118, 119,   3, 120,\n",
              "        121, 122, 123,  36, 124,  30, 118, 109, 125,   3, 126, 127,  11,  59,\n",
              "        125,   3, 128, 126, 127, 129, 123, 130, 131, 132,  30,   2,   3, 133,\n",
              "         47,  43, 115,   3, 111, 116,  11, 111, 112,   2, 135, 136, 137, 138,\n",
              "         30,   2,   3,  85, 139, 140,   3, 141, 122,   3, 116,  11,   6, 143,\n",
              "        144, 145,   8,  59, 109,  60, 147, 148,   3, 149, 126,  11,  59, 150,\n",
              "        151, 152, 153, 154, 155, 111, 112,  30, 109, 156,  12,  31, 108, 109,\n",
              "        157,  25,  13, 158, 159,  11,  30,   3,  10, 160,  25,  26,  22,   2,\n",
              "        161,  33, 158, 162, 163, 164,  88, 165,  30, 157, 166,  20, 118, 109,\n",
              "        167,   3,  10, 129,   3, 168,  11,  20,  39, 118, 167,   3,  10, 169,\n",
              "        170, 133,  30, 109, 171, 129,   3, 168,  20,  59, 109,  60, 172,  16,\n",
              "        173, 115,   3, 174, 175,  11,  20, 176,  39, 177,  20, 115, 178, 116,\n",
              "         59,  60, 179, 129, 123, 130,  30, 156, 109,  40,  16, 180,   3, 181,\n",
              "         22, 182,  11, 104, 183,  30, 184,  59,  60, 185,  33,  75,  22, 186,\n",
              "         30,  58, 156,  99,   7,  97,  98, 129,   3,  10,  11,  20, 187,  99,\n",
              "          7,  97,  98,  59,  60, 188,  22, 189,  30, 118,  58, 190,  39,  33,\n",
              "        191,  11, 118, 192, 193, 169, 194, 195, 196, 198, 199, 156,  58,  40,\n",
              "         16,  41, 200,  42,  11,  42, 201,  60, 202, 203, 200, 204, 205,  30,\n",
              "         58, 206,   3, 207, 208, 169, 176,  11,  20,   3,  10,  34,  13, 210,\n",
              "         35,  36,  37,  30,   2,   3, 211,  43,   3,  35,  36,  11, 211,   2,\n",
              "        212, 213,  25,   3, 214,  43, 215,  30, 108, 109, 216, 217, 218, 219,\n",
              "          3,  31, 131, 220,   3, 215,  30,   1,   2,   3, 221, 222,  11,   2,\n",
              "         13, 224, 221, 222,  25,   3, 214,  43, 215,  30, 157, 225, 226, 227,\n",
              "         22, 228,  16,  41,  42,  30,   1, 229, 109, 156,  11, 190, 193, 231,\n",
              "        152,  33, 232, 215, 233,  30, 132, 191, 236, 118, 109, 237,   3, 238,\n",
              "        239, 240,   3, 205,  11, 118, 119, 239, 241, 138, 241, 123,  36,   2,\n",
              "        242,  30, 131, 243, 115, 244,  20,  39,  59, 245, 246, 235,   3,  10,\n",
              "        217, 247, 248, 214,  30, 250, 211,   2, 251, 185,  11, 246,   2, 251,\n",
              "        185, 252,  16,   3, 253,  31,  32,  22, 254, 255, 256,  30, 118, 109,\n",
              "        257, 258, 131,   3, 112,  11, 118, 180, 123, 258, 259,   3, 260, 261,\n",
              "        179, 129, 123, 130,  30, 109, 167,   3,  10, 166,  20, 118, 109, 262,\n",
              "        257, 258,  25, 174, 116,  11,  20,  39, 118, 263, 258, 198,  16, 174,\n",
              "        116, 241, 264,  30,  22, 266, 267, 198, 191,   2,   3, 268,  16, 113,\n",
              "          3, 265,  11, 104, 269, 268,  64, 271,  43, 115,  35,  42, 273, 115,\n",
              "        274,  22, 275, 157, 276, 166,  30, 146, 118, 109, 206,  33, 178,  49,\n",
              "         11,  59, 113, 151, 277, 129, 123, 130,  16, 278, 279,  49,  30, 266,\n",
              "        267, 280, 129,  12,  10,  11,  20, 266, 267,   2, 280, 281, 266,   2,\n",
              "        251, 282,  30,   3, 267, 283,  64,  22,  92, 285, 287, 289, 285, 116,\n",
              "        292, 293, 294])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHaeSuI_nJX",
        "outputId": "57ddf3b7-c7d8-4896-813b-e438692f94a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "731"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7ZUeD3l6_oZ3"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 100)\n",
        "        self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "        self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(\n",
        "            embedded\n",
        "        )\n",
        "        output = self.fc(final_hidden_state.squeeze(0))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "outputs": [],
      "source": [
        "model = LSTMModel(len(vocab)) # class LSTMModel(nn.Module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Lvm7W6L1X6P1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwq43NRYD3q",
        "outputId": "bfa82df5-0594-44e9-beb7-87c24db3c007"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(295, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=295, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1faORN1VYFdu"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "7bc238c9-56d3-4558-db07-41d2474aa64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 128.8088\n",
            "Epoch: 2, Loss: 116.0142\n",
            "Epoch: 3, Loss: 106.5071\n",
            "Epoch: 4, Loss: 98.9402\n",
            "Epoch: 5, Loss: 91.3713\n",
            "Epoch: 6, Loss: 83.4184\n",
            "Epoch: 7, Loss: 76.1104\n",
            "Epoch: 8, Loss: 69.3036\n",
            "Epoch: 9, Loss: 62.6884\n",
            "Epoch: 10, Loss: 56.2215\n",
            "Epoch: 11, Loss: 50.3249\n",
            "Epoch: 12, Loss: 44.9324\n",
            "Epoch: 13, Loss: 39.9002\n",
            "Epoch: 14, Loss: 35.3306\n",
            "Epoch: 15, Loss: 31.1960\n",
            "Epoch: 16, Loss: 27.6105\n",
            "Epoch: 17, Loss: 24.3909\n",
            "Epoch: 18, Loss: 21.7311\n",
            "Epoch: 19, Loss: 19.3209\n",
            "Epoch: 20, Loss: 17.2693\n",
            "Epoch: 21, Loss: 15.4651\n",
            "Epoch: 22, Loss: 13.9973\n",
            "Epoch: 23, Loss: 12.7344\n",
            "Epoch: 24, Loss: 11.5818\n",
            "Epoch: 25, Loss: 10.6119\n",
            "Epoch: 26, Loss: 9.7769\n",
            "Epoch: 27, Loss: 9.0229\n",
            "Epoch: 28, Loss: 8.4683\n",
            "Epoch: 29, Loss: 7.9159\n",
            "Epoch: 30, Loss: 7.4164\n",
            "Epoch: 31, Loss: 7.0127\n",
            "Epoch: 32, Loss: 6.6495\n",
            "Epoch: 33, Loss: 6.4333\n",
            "Epoch: 34, Loss: 6.1102\n",
            "Epoch: 35, Loss: 5.8471\n",
            "Epoch: 36, Loss: 5.6839\n",
            "Epoch: 37, Loss: 5.4117\n",
            "Epoch: 38, Loss: 5.2538\n",
            "Epoch: 39, Loss: 5.0740\n",
            "Epoch: 40, Loss: 4.9562\n",
            "Epoch: 41, Loss: 4.8033\n",
            "Epoch: 42, Loss: 4.6462\n",
            "Epoch: 43, Loss: 4.5593\n",
            "Epoch: 44, Loss: 4.3926\n",
            "Epoch: 45, Loss: 4.3315\n",
            "Epoch: 46, Loss: 4.2155\n",
            "Epoch: 47, Loss: 4.1468\n",
            "Epoch: 48, Loss: 4.0870\n",
            "Epoch: 49, Loss: 4.0602\n",
            "Epoch: 50, Loss: 3.9276\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_x, batch_y in dataloader:\n",
        "\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(batch_x)\n",
        "\n",
        "        loss = criterion(output, batch_y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "outputs": [],
      "source": [
        "# prediction\n",
        "\n",
        "\n",
        "def prediction(model, vocab, text):\n",
        "\n",
        "    # tokenize\n",
        "    tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "    # text -> numerical indices\n",
        "    numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "    # padding\n",
        "    padded_text = torch.tensor(\n",
        "        [0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long\n",
        "    ).unsqueeze(0)\n",
        "\n",
        "    # send to model\n",
        "    output = model(padded_text)\n",
        "\n",
        "    # predicted index\n",
        "    value, index = torch.max(output, dim=1)\n",
        "\n",
        "    # merge with text\n",
        "    return text + \" \" + list(vocab.keys())[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VsRgcJysbGCg",
        "outputId": "96e00ee4-a7ee-4549-cd63-297dde6a27eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes. The program starts from fundamentals'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction(model, vocab, \"Yes. The program starts from\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "0a36a6da-8118-4989-b754-e69826765f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You will find the month-wise\n",
            "You will find the month-wise class\n",
            "You will find the month-wise class schedule\n",
            "You will find the month-wise class schedule in\n",
            "You will find the month-wise class schedule in your\n",
            "You will find the month-wise class schedule in your dashboard\n",
            "You will find the month-wise class schedule in your dashboard after\n",
            "You will find the month-wise class schedule in your dashboard after registration\n",
            "You will find the month-wise class schedule in your dashboard after registration .\n",
            "You will find the month-wise class schedule in your dashboard after registration . after\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"You will find the\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "    output_text = prediction(model, vocab, input_text)\n",
        "    print(output_text)\n",
        "    input_text = output_text\n",
        "    time.sleep(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JXsV4AnNXNnw"
      },
      "outputs": [],
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py7o0rJJc5pm",
        "outputId": "d6de41b2-e157-4da6-8dde-cd27de358a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 94.80%\n"
          ]
        }
      ],
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "air_ds_projects",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
