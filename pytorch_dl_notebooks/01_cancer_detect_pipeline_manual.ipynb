{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5b3a9a",
   "metadata": {},
   "source": [
    "## Binary classification using PyTorch manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "03caed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a27ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../datasets/breast_canc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "badad1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b1f05495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9d73962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b2bce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns={\"id\", \"Unnamed: 32\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943743c",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "15fabd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    df.drop(columns={\"diagnosis\"}), df[\"diagnosis\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "87084cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9de11840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b837ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46649743, -0.13728933, -0.44421138, ..., -0.19435087,\n",
       "         0.17275669,  0.20372995],\n",
       "       [ 1.36536344,  0.49866473,  1.30551088, ...,  0.99177862,\n",
       "        -0.561211  , -1.00838949],\n",
       "       [ 0.38006578,  0.06921974,  0.40410139, ...,  0.57035018,\n",
       "        -0.10783139, -0.20629287],\n",
       "       ...,\n",
       "       [-0.73547237, -0.99852603, -0.74138839, ..., -0.27741059,\n",
       "        -0.3820785 , -0.32408328],\n",
       "       [ 0.02898271,  2.0334026 ,  0.0274851 , ..., -0.49027026,\n",
       "        -1.60905688, -0.33137507],\n",
       "       [ 1.87216885,  2.80077153,  1.80354992, ...,  0.7925579 ,\n",
       "        -0.05868885, -0.09467243]], shape=(114, 30))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09e3b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "\n",
    "ytrain = enc.fit_transform(ytrain)\n",
    "ytest = enc.transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e996185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89547520",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b046f0",
   "metadata": {},
   "source": [
    "Numpy array to pytorch tensor conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bedd7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "858fd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tensor = torch.from_numpy(xtrain)\n",
    "xtest_tensor = torch.from_numpy(xtest)\n",
    "ytrain_tensor = torch.from_numpy(ytrain)\n",
    "ytest_tensor = torch.from_numpy(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc7d1e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.44075296, -0.43531947, -1.36208497, ...,  0.9320124 ,\n",
       "         2.09724217,  1.88645014],\n",
       "       [ 1.97409619,  1.73302577,  2.09167167, ...,  2.6989469 ,\n",
       "         1.89116053,  2.49783848],\n",
       "       [-1.39998202, -1.24962228, -1.34520926, ..., -0.97023893,\n",
       "         0.59760192,  0.0578942 ],\n",
       "       ...,\n",
       "       [ 0.04880192, -0.55500086, -0.06512547, ..., -1.23903365,\n",
       "        -0.70863864, -1.27145475],\n",
       "       [-0.03896885,  0.10207345, -0.03137406, ...,  1.05001236,\n",
       "         0.43432185,  1.21336207],\n",
       "       [-0.54860557,  0.31327591, -0.60350155, ..., -0.61102866,\n",
       "        -0.3345212 , -0.84628745]], shape=(455, 30))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5c8688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4408, -0.4353, -1.3621,  ...,  0.9320,  2.0972,  1.8865],\n",
       "        [ 1.9741,  1.7330,  2.0917,  ...,  2.6989,  1.8912,  2.4978],\n",
       "        [-1.4000, -1.2496, -1.3452,  ..., -0.9702,  0.5976,  0.0579],\n",
       "        ...,\n",
       "        [ 0.0488, -0.5550, -0.0651,  ..., -1.2390, -0.7086, -1.2715],\n",
       "        [-0.0390,  0.1021, -0.0314,  ...,  1.0500,  0.4343,  1.2134],\n",
       "        [-0.5486,  0.3133, -0.6035,  ..., -0.6110, -0.3345, -0.8463]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "057ef30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa489116",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3eb9ce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "45410da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 ip feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7f2d81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, X):\n",
    "\n",
    "        # random weight and bias init\n",
    "        self.weights = torch.rand(\n",
    "            X.shape[1], 1, dtype=torch.float64, requires_grad=True\n",
    "        )  # x.shape1->input feat dim,\n",
    "        self.bias = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    #  calculate ypred ..forward pass\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        z = torch.matmul(X, self.weights) + self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "\n",
    "    # use binary cross entropy\n",
    "\n",
    "    def loss_function(self, y_pred, y):\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "        # Calculate loss\n",
    "        loss = -(\n",
    "            ytrain_tensor * torch.log(y_pred)\n",
    "            + (1 - ytrain_tensor) * torch.log(1 - y_pred)\n",
    "        ).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "901a85b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp parameters\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e38b5940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c0cdeeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0584],\n",
       "        [0.9248],\n",
       "        [0.7726],\n",
       "        [0.8478],\n",
       "        [0.0250],\n",
       "        [0.1282],\n",
       "        [0.9108],\n",
       "        [0.0161],\n",
       "        [0.0552],\n",
       "        [0.5445],\n",
       "        [0.7770],\n",
       "        [0.7250],\n",
       "        [0.0671],\n",
       "        [0.0363],\n",
       "        [0.0665],\n",
       "        [0.5716],\n",
       "        [0.9791],\n",
       "        [0.4100],\n",
       "        [0.6103],\n",
       "        [0.6356],\n",
       "        [0.2799],\n",
       "        [0.9517],\n",
       "        [0.0253],\n",
       "        [0.9637],\n",
       "        [0.2585],\n",
       "        [0.0933],\n",
       "        [0.4623],\n",
       "        [0.9510],\n",
       "        [0.1441],\n",
       "        [0.7289]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = SimpleNN(xtrain_tensor)\n",
    "model1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bc25c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model1.weights.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dc6a3fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b1057",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9f996",
   "metadata": {},
   "source": [
    "```py\n",
    "class SimpleNN:\n",
    "    def __init__(self, X):\n",
    "\n",
    "        # random weight and bias init\n",
    "        self.weights = torch.rand(\n",
    "            X.shape[1], 1, dtype=torch.float64, requires_grad=True\n",
    "        )  # x.shape1->input feat dim,\n",
    "        self.bias = torch.rand(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    #  calculate ypred ..forward pass\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        z = torch.matmul(X, self.weights) + self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "\n",
    "    # use binary cross entropy\n",
    "\n",
    "    def loss_function(self, y_pred, y):\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "        # Calculate loss\n",
    "        loss = -(\n",
    "            ytrain_tensor * torch.log(y_pred)\n",
    "            + (1 - ytrain_tensor) * torch.log(1 - y_pred)\n",
    "        ).mean()\n",
    "        return loss\n",
    "```\n",
    "------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "60eeaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ephocs 1 Loss:  3.528149846675087\n",
      "Ephocs 2 Loss:  3.396875833663181\n",
      "Ephocs 3 Loss:  3.2586190495031557\n",
      "Ephocs 4 Loss:  3.113620677989027\n",
      "Ephocs 5 Loss:  2.9664115252750145\n",
      "Ephocs 6 Loss:  2.812668950989177\n",
      "Ephocs 7 Loss:  2.6549872958156393\n",
      "Ephocs 8 Loss:  2.4926062266720246\n",
      "Ephocs 9 Loss:  2.3279856293099392\n",
      "Ephocs 10 Loss:  2.1589047345486003\n",
      "Ephocs 11 Loss:  1.9955115545113102\n",
      "Ephocs 12 Loss:  1.8376762882035802\n",
      "Ephocs 13 Loss:  1.682800364987335\n",
      "Ephocs 14 Loss:  1.5340755757155526\n",
      "Ephocs 15 Loss:  1.393514170479711\n",
      "Ephocs 16 Loss:  1.2642348957743668\n",
      "Ephocs 17 Loss:  1.1518528961347858\n",
      "Ephocs 18 Loss:  1.0573645751418377\n",
      "Ephocs 19 Loss:  0.9808612426741937\n",
      "Ephocs 20 Loss:  0.9212338675194659\n",
      "Ephocs 21 Loss:  0.8762414976356363\n",
      "Ephocs 22 Loss:  0.8429985659379408\n",
      "Ephocs 23 Loss:  0.8185756372545414\n",
      "Ephocs 24 Loss:  0.8004320163005526\n",
      "Ephocs 25 Loss:  0.7865995070236501\n",
      "Ephocs 26 Loss:  0.7756724745694931\n",
      "Ephocs 27 Loss:  0.7667039150979487\n",
      "Ephocs 28 Loss:  0.7590824958333158\n",
      "Ephocs 29 Loss:  0.7524248689945262\n",
      "Ephocs 30 Loss:  0.7464935179271122\n"
     ]
    }
   ],
   "source": [
    "# Training pipeline\n",
    "\n",
    "# create model\n",
    "model = SimpleNN(xtrain_tensor)\n",
    "\n",
    "# define loop\n",
    "\n",
    "\n",
    "# forward pass\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    ypred = model.forward_pass(xtrain_tensor)\n",
    "\n",
    "    # loss calc\n",
    "\n",
    "    loss = model.loss_function(ypred, ytrain_tensor)\n",
    "\n",
    "    # backward pass\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # wnew=wold-lr*(Del(L)/delw)\n",
    "\n",
    "    # parameter update\n",
    "    with torch.no_grad():\n",
    "        model.weights -= learning_rate * model.weights.grad\n",
    "        model.bias -= learning_rate * model.bias.grad\n",
    "\n",
    "    # solve gradient accumulate problem\n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    print(\"Ephocs\", epoch + 1, \"Loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8bac6021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1754], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee1b38",
   "metadata": {},
   "source": [
    "Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "26f91c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6228070259094238\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "with torch.no_grad():\n",
    "  y_pred = model.forward_pass(xtest_tensor)\n",
    "  y_pred = (y_pred > 0.9).float()\n",
    "  accuracy = (y_pred == ytest_tensor).float().mean()\n",
    "  print(f'Accuracy: {accuracy.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bb89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_ds_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
